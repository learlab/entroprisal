{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907973ae",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the package and load the reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d26ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from entroprisal import (\n",
    "    TokenEntropisalCalculator,\n",
    "    CharacterEntropisalCalculator,\n",
    "    RestOfWordEntropisalCalculator,\n",
    ")\n",
    "from entroprisal.utils import load_4grams, load_google_books_words\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db7b83",
   "metadata": {},
   "source": [
    "## 1. Token-Level Entropy and Surprisal\n",
    "\n",
    "Token-level metrics use n-gram frequencies to calculate information content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6158628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 4-gram reference data\n",
    "ngrams = load_4grams(\"aw\")  # \"aw\" = all words variant\n",
    "\n",
    "# Initialize calculator\n",
    "token_calc = TokenEntropisalCalculator(ngrams, min_frequency=100)\n",
    "\n",
    "print(\"Token calculator initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c010939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for a single sequence\n",
    "tokens = [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\n",
    "metrics = token_calc.calculate_metrics(tokens)\n",
    "\n",
    "print(\"Metrics for token sequence:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d251515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing multiple sequences\n",
    "token_sequences = [\n",
    "    [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n",
    "    [\"a\", \"quick\", \"brown\", \"fox\"],\n",
    "    [\"hello\", \"world\", \"this\", \"is\", \"a\", \"test\"],\n",
    "]\n",
    "\n",
    "results_df = token_calc.calculate_batch(token_sequences)\n",
    "print(\"\\nBatch processing results:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6165c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed analysis showing per-token metrics\n",
    "detailed = token_calc.get_detailed_ngram_analysis(tokens)\n",
    "\n",
    "print(\"\\nDetailed analysis for trigrams (n=3):\")\n",
    "if 3 in detailed and len(detailed[3]) > 0:\n",
    "    detailed[3].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c63e0",
   "metadata": {},
   "source": [
    "## 2. Character-Level Entropy and Surprisal\n",
    "\n",
    "Character-level metrics analyze transition probabilities and information content between characters within words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6afad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word frequency reference data\n",
    "words_df = load_google_books_words()\n",
    "\n",
    "print(f\"Loaded {len(words_df):,} words from Google Books\")\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9aca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize character entropy calculator\n",
    "char_calc = CharacterEntropisalCalculator(words_df)\n",
    "\n",
    "print(\"Character calculator initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for a text sample\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "char_metrics = char_calc.calculate_metrics(text)\n",
    "\n",
    "print(\"Character-level metrics:\")\n",
    "for key, value in char_metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02038c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing\n",
    "texts = [\n",
    "    \"Simple text with common words\",\n",
    "    \"More complex vocabulary requires careful analysis\",\n",
    "    \"Short text\",\n",
    "]\n",
    "\n",
    "char_results = char_calc.calculate_batch(texts)\n",
    "print(\"\\nBatch character entropy results:\")\n",
    "char_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646979aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up entropy and surprisal for specific character sequences\n",
    "print(\"Entropy lookups:\")\n",
    "print(f\"  Character 'q': {char_calc.get_character_entropy('q'):.4f}\")\n",
    "print(f\"  Character 't': {char_calc.get_character_entropy('t'):.4f}\")\n",
    "print(f\"  Bigraph 'th': {char_calc.get_bigraph_entropy('th'):.4f}\")\n",
    "print(f\"  Bigraph 'qu': {char_calc.get_bigraph_entropy('qu'):.4f}\")\n",
    "print(f\"  Trigraph 'the': {char_calc.get_trigraph_entropy('the'):.4f}\")\n",
    "\n",
    "print(\"\\nSurprisal lookups:\")\n",
    "print(f\"  'u' after 'q': {char_calc.get_character_surprisal('q', 'u'):.4f}\")\n",
    "print(f\"  'h' after 't': {char_calc.get_character_surprisal('t', 'h'):.4f}\")\n",
    "print(f\"  'th' at the end of a word: {char_calc.get_bigraph_surprisal('th', '#'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e22779",
   "metadata": {},
   "source": [
    "## 3. Rest-of-Word Entropy and Surprisal (Character-Level, Bidirectional)\n",
    "\n",
    "Rest-of-word metrics analyze character-level entropy and surprisal for predicting the remaining characters of a word from its beginning (left-to-right) or end (right-to-left)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize rest-of-word calculator (uses same reference data as character calculator)\n",
    "word_calc = RestOfWordEntropisalCalculator(words_df)\n",
    "\n",
    "print(\"Rest-of-word calculator initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ea28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for a text sample\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "word_metrics = word_calc.calculate_metrics(text)\n",
    "\n",
    "print(\"Word-level bidirectional metrics:\")\n",
    "for key, value in word_metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different texts\n",
    "texts = [\"Simple words\", \"Complex multisyllabic terminology\", \"The cat sat on the mat\"]\n",
    "\n",
    "word_results = word_calc.calculate_batch(texts)\n",
    "print(\"\\nBatch word entropy results:\")\n",
    "word_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up word frequency\n",
    "words_to_check = [\"the\", \"quick\", \"antidisestablishmentarianism\", \"xyz\"]\n",
    "\n",
    "print(\"Word frequencies in reference corpus:\")\n",
    "for word in words_to_check:\n",
    "    freq = word_calc.get_word_frequency(word)\n",
    "    print(f\"  '{word}': {freq:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290cc5b",
   "metadata": {},
   "source": [
    "## 4. Combining Multiple Metrics\n",
    "\n",
    "You can combine metrics from different calculators for comprehensive text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7346fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze multiple texts with all three calculators\n",
    "sample_texts = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"A quick brown fox jumps over the lazy dog.\",\n",
    "    \"Complex linguistic analysis requires sophisticated tools.\",\n",
    "]\n",
    "\n",
    "# Character metrics\n",
    "char_df = char_calc.calculate_batch(sample_texts)\n",
    "char_df[\"text\"] = sample_texts\n",
    "\n",
    "# Word metrics\n",
    "word_df = word_calc.calculate_batch(sample_texts)\n",
    "word_df[\"text\"] = sample_texts\n",
    "\n",
    "# Combine\n",
    "combined = pd.merge(char_df, word_df, on=\"text\", suffixes=(\"_char\", \"_word\"))\n",
    "\n",
    "print(\"Combined metrics:\")\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbeb7ef",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Token-level entropy and surprisal calculation\n",
    "2. Character-level transition entropy\n",
    "3. Bidirectional rest-of-word entropy\n",
    "4. Combining multiple metrics\n",
    "\n",
    "For more information, see the [README.md](../README.md) and API documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entroprisal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
